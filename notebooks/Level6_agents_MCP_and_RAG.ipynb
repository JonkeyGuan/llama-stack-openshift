{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
   "metadata": {},
   "source": [
    "# Level 6: Agents, MCP and RAG \n",
    "\n",
    "This notebook is an extension of the [Level 5 Agentic & MCP notebook](./Level5_agents_and_mcp.ipynb) with the addition of RAG.\n",
    "This tutorial is for developers who are already familiar with [agentic RAG workflows](./Level4_RAG_agent.ipynb). This tutorial will highlight a couple of slightly more advanced use cases for agents where a single tool call is insufficient to complete the required task. Here we will rely on both agentic RAG and MCP server to expand our agents capabilities.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers the following steps:\n",
    "1. Review OpenShift logs for a failing pod.\n",
    "2. Categorize the pod and summarize its error.\n",
    "3. Search available troubleshooting documentations for ideas on how to resolve the error.\n",
    "4. Send a Slack message to the ops team with a brief summary of the error and next steps to take.\n",
    "\n",
    "### MCP Tools:\n",
    "\n",
    "#### OpenShift MCP Server\n",
    "Throughout this notebook we will be relying on the [kubernetes-mcp-server](https://github.com/manusa/kubernetes-mcp-server) by [manusa](https://github.com/manusa) to interact with our OpenShift cluster. Please see installation instructions below if you do not already have this deployed in your environment. \n",
    "\n",
    "* [OpenShift MCP installation instructions](../../../kubernetes/mcp-servers/openshift-mcp/README.md)\n",
    "\n",
    "#### Slack MCP Server\n",
    "We will also be using the [Slack MCP Server](https://github.com/modelcontextprotocol/servers-archived/tree/main/src/slack) in this notebook. Please see installation instructions below if you do not already have this deployed in your environment. \n",
    "\n",
    "* [Slack MCP installation instructions](../../../kubernetes/mcp-servers/slack-mcp/README.md)\n",
    "\n",
    "### Pre-Requisites\n",
    "\n",
    "Before starting, ensure you have the following:\n",
    "- A running Llama Stack server\n",
    "- A running Slack MCP server. Refer to our [documentation](https://github.com/opendatahub-io/llama-stack-demos/tree/main/kubernetes/mcp-servers/slack-mcp) on how you can set this up on your OpenShift cluster\n",
    "- Access to an OpeShift cluster with a deployment of the [OpenShift MCP server](../../../kubernetes/mcp-servers/openshift-mcp) (see the [deployment manifests](https://github.com/opendatahub-io/llama-stack-on-ocp/tree/main/kubernetes/mcp-servers/openshift-mcp) for assistance with this).\n",
    "\n",
    "## Setting Up this Notebook\n",
    "We will initialize our environment as described in detail in our [\\\"Getting Started\\\" notebook](./Level0_getting_started_with_Llama_Stack.ipynb). Please refer to it for additional explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fc0a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for communication with Llama Stack\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client import Agent\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "from llama_stack_client import RAGDocument\n",
    "from llama_stack_client.lib.agents.react.agent import ReActAgent\n",
    "from llama_stack_client.lib.agents.react.tool_parser import ReActOutput\n",
    "\n",
    "# pretty print of the results returned from the model/agent\n",
    "from termcolor import cprint\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from src.utils import step_printer\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08281062-f222-4443-a7bc-0f6166aab36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server\n",
      "Inference Parameters:\n",
      "\tModel: qwen\n",
      "\tSampling Parameters: {'strategy': {'type': 'greedy'}, 'max_tokens': 2048}\n",
      "\tstream: False\n"
     ]
    }
   ],
   "source": [
    "base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "\n",
    "\n",
    "# Tavily search API key is required for some of our demos and must be provided to the client upon initialization.\n",
    "# We will cover it in the agentic demos that use the respective tool. Please ignore this parameter for all other demos.\n",
    "tavily_search_api_key = os.getenv(\"TAVILY_SEARCH_API_KEY\")\n",
    "if tavily_search_api_key is None:\n",
    "    provider_data = None\n",
    "else:\n",
    "    provider_data = {\"tavily_search_api_key\": tavily_search_api_key}\n",
    "\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data=provider_data\n",
    ")\n",
    "\n",
    "print(f\"Connected to Llama Stack server\")\n",
    "\n",
    "# model_id will later be used to pass the name of the desired inference model to Llama Stack Agents/Inference APIs\n",
    "# model_id = \"granite\"\n",
    "model_id = \"qwen\"\n",
    "\n",
    "temperature = float(os.getenv(\"TEMPERATURE\", 0.0))\n",
    "if temperature > 0.0:\n",
    "    top_p = float(os.getenv(\"TOP_P\", 0.95))\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": temperature, \"top_p\": top_p}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "max_tokens = int(os.getenv(\"MAX_TOKENS\", 512))\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "# For this demo, we are using Milvus Lite, which is our preferred solution. Any other Vector DB supported by Llama Stack can be used.\n",
    "\n",
    "# RAG vector DB settings\n",
    "VECTOR_DB_EMBEDDING_MODEL = os.getenv(\"VDB_EMBEDDING\")\n",
    "VECTOR_DB_EMBEDDING_DIMENSION = int(os.getenv(\"VDB_EMBEDDING_DIMENSION\", 384))\n",
    "VECTOR_DB_CHUNK_SIZE = int(os.getenv(\"VECTOR_DB_CHUNK_SIZE\", 512))\n",
    "VECTOR_DB_PROVIDER_ID = os.getenv(\"VDB_PROVIDER\")\n",
    "\n",
    "# Unique DB ID for session\n",
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\"\n",
    "\n",
    "stream_env = os.getenv(\"STREAM\", \"False\")\n",
    "# the Boolean 'stream' parameter will later be passed to Llama Stack Agents/Inference APIs\n",
    "# any value non equal to 'False' will be considered as 'True'\n",
    "stream = (stream_env != \"False\")\n",
    "\n",
    "print(f\"Inference Parameters:\\n\\tModel: {model_id}\\n\\tSampling Parameters: {sampling_params}\\n\\tstream: {stream}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66044170",
   "metadata": {},
   "source": [
    "### Validate tools are available in our Llama Stack instance\n",
    "\n",
    "We will be using the [OpenShift MCP Server](https://github.com/manusa/kubernetes-mcp-server) and the [Slack MCP Server](https://github.com/modelcontextprotocol/servers/tree/main/src/slack) for performing this task. If you haven't already, you can follow the instructions [here](https://github.com/opendatahub-io/llama-stack-demos/tree/main/kubernetes/mcp-servers/slack-mcp#setting-up-on-ocp) to install the Slack MCP server and the instructions [here](https://github.com/opendatahub-io/llama-stack-demos/tree/main/kubernetes/mcp-servers/openshift-mcp#steps-for-deploying-the-openshift-mcp-server-on-openshift) to install the OpenShift MCP server. Once we confirm that the OpenShift and Slack MCP servers are running and configured to your Llama Stack server, we can then move on to defining an agent to help with our task.\n",
    "\n",
    "#### Registering tools on Llama Stack\n",
    "When an instance of llama stack is redeployed your tools need to re-registered. Also if a tool is already registered with a llama stack instance, if you try to register one with the same `toolgroup_id`, llama stack will throw you an error.\n",
    "\n",
    "For this reason it is recommended to include some code to validate your tools and toolgroups. This is where the `mcp_url` comes into play. The following code will check that the `builtin::rag`,`mcp::openshift`  and `mcp::slack` tools are registered as tools, but if any mcp tool is not listed there, it will attempt to register it using the mcp url.\n",
    "\n",
    "If you are running the MCP server from source, the default value for this is: `http://localhost:8000/sse`.\n",
    "\n",
    "If you are running the MCP server from a container, the default value for this is: `http://host.containers.internal:8000/sse`.\n",
    "\n",
    "Make sure to pass the corresponding MCP URL for the server you are trying to register/validate tools for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Llama Stack server is already registered with the following tool groups: {'builtin::websearch', 'builtin::rag', 'mcp::slack', 'mcp::openshift'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Enter your MCP server URL here\n",
    "ocp_mcp_url = os.getenv(\"REMOTE_OCP_MCP_URL\") # Optional: enter your MCP server url here\n",
    "slack_mcp_url = os.getenv(\"REMOTE_SLACK_MCP_URL\") # Optional: enter your MCP server url here\n",
    "\n",
    "# Get list of registered tools and extract their toolgroup IDs\n",
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [tool.toolgroup_id for tool in registered_tools]\n",
    "\n",
    "if  \"builtin::rag\" not in registered_toolgroups: # Required\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"builtin::rag\",\n",
    "        provider_id=\"milvus\"\n",
    "    )\n",
    "\n",
    "if \"mcp::openshift\" not in registered_toolgroups: # required\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::openshift\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\":ocp_mcp_url},\n",
    "    )\n",
    "\n",
    "if \"mcp::slack\" not in registered_toolgroups: # required\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::slack\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\":slack_mcp_url},\n",
    "    )\n",
    "\n",
    "# Log the current toolgroups registered\n",
    "print(f\"Your Llama Stack server is already registered with the following tool groups: {set(registered_toolgroups)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8d3f8",
   "metadata": {},
   "source": [
    "## Discover and report solutions to errors that might be happening on my OpenShift Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f6993e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We will now try to use an agent to:\n",
    "- **Retrieve the logs of a failing pod running on OpenShift**\n",
    "- **Use RAG to find solutions to the errors in the pod logs based on OpenShift troubleshooting documents**\n",
    "- **Send a summary of the solution as a message on Slack.**\n",
    "\n",
    "### Pod with simulated error logs\n",
    "\n",
    "**Important** - In the [Level5 Agents and MCP notebook](./Level5_agents_and_mcp.ipynb) we deployed a pod called `slack-test` on an OpenShift cluster that generates simulated error logs. For the purpose of testing the pod log retrieval, we will be using that pod for this notebook and assume that it is already running on your cluster. **If you haven't already, please make sure to go through the Level5 notebook before continuing this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85664f8",
   "metadata": {},
   "source": [
    "### RAG: Indexing the Documents\n",
    "\n",
    "We will be leveraging RAG to help us find solutions from OpenShift troubleshooting documents for debugging the logs of erroneous pods running on OpenShift. We will need to:\n",
    "- Initialize a new document collection in the target vector DB. All parameters related to the vector DB, such as the embedding model and dimension, must be specified here.\n",
    "- Provide a list of document URLs to the RAG tool. Llama Stack will handle fetching, conversion and chunking of the documents' content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8f4dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/rag-tool/insert \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# define and register the document collection to be used\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=VECTOR_DB_EMBEDDING_MODEL,\n",
    "    embedding_dimension=VECTOR_DB_EMBEDDING_DIMENSION,\n",
    "    provider_id=VECTOR_DB_PROVIDER_ID,\n",
    ")\n",
    "\n",
    "# ingest the documents into the newly created document collection\n",
    "urls = [\n",
    "    (\"https://docs.redhat.com/en/documentation/openshift_container_platform/4.11/pdf/support/OpenShift_Container_Platform-4.11-Support-en-US.pdf\", \"application/pdf\"),\n",
    "]\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"num-{i}\",\n",
    "        content=url,\n",
    "        mime_type=url_type,\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, (url, url_type) in enumerate(urls)\n",
    "]\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=VECTOR_DB_CHUNK_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf70ace-b704-4379-aa88-3c793cc4f959",
   "metadata": {},
   "source": [
    "### System Prompt for LLM model\n",
    "\n",
    "**Note:** If you have multiple models configured with your Llama Stack server, you can choose which one to run your queries against. When switching to a different model, you may need to adjust the system prompt to align with that model’s expected behavior. Many models provide recommended system prompts for optimal and reliable outputs these are typically documented on their respective websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3136e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prompt= \"\"\"You are a helpful assistant. You have access to a number of tools.\n",
    "Whenever a tool is called, be sure return the Response in a friendly and helpful tone.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b675f2a",
   "metadata": {},
   "source": [
    "## Defining our Agent - Prompt Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b340e517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=builtin%3A%3Arag \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aopenshift \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aslack \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/b9f4bcbd-1d38-4aee-99ad-c2ea23ad1126/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/b9f4bcbd-1d38-4aee-99ad-c2ea23ad1126/session/04a77331-70a3-4013-bbee-3a7bc7044962/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: pods_log, Arguments: {'name': 'slack-test', 'namespace': 'llama-serve'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/b9f4bcbd-1d38-4aee-99ad-c2ea23ad1126/session/04a77331-70a3-4013-bbee-3a7bc7044962/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m<think>\n",
      "Okay, let's see. The user asked to view the logs for the pod named slack-test in the llama-serve namespace and categorize them as normal or error. I called the pods_log function with the correct name and namespace. The response from the tool shows some log entries. \n",
      "\n",
      "Looking at the logs: \"Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n\" \n",
      "\n",
      "These entries indicate that the container started but then failed with an unknown error. The error details mention it's an unexpected issue during startup, and possible causes are listed. Since there's a \"Failure\" and \"Error\" in the logs, this clearly falls under the error category.\n",
      "\n",
      "I need to present this to the user by first showing the logs and then categorizing them. I should explain the categorization based on the error messages found. Also, maybe suggest checking the potential causes mentioned in the logs. Let me structure the response to be clear and helpful.\n",
      "</think>\n",
      "\n",
      "The logs for the `slack-test` pod in the `llama-serve` namespace are as follows:\n",
      "\n",
      "```\n",
      "Starting container...\n",
      "Failure: Unknown Error\n",
      "Error details: Container failed due to an unexpected issue during startup.\n",
      "Potential cause: Missing dependencies, configuration errors, or permission issues.\n",
      "```\n",
      "\n",
      "**Categorization:** **Error**  \n",
      "The logs explicitly indicate a failure during container startup, with an \"Unknown Error\" and potential causes listed (missing dependencies, configuration issues, or permissions problems). This is not normal operation.  \n",
      "\n",
      "**Next Steps:**  \n",
      "- Check the container's configuration for missing dependencies or misconfigurations.  \n",
      "- Verify permissions for resources the container is trying to access.  \n",
      "- Review the container image for compatibility or startup script issues.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: knowledge_search, Arguments: {'query': 'Kubernetes pod failure unknown error during startup missing dependencies configuration errors permission issues'}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon &lt;node_name&gt;\\n$ oc adm drain &lt;node_name&gt; --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability (GA) status, whereas other\\n.. for pod in $(crictl pods -q); do if [[ \"$(crictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network)\" != \"\\nMetadata: {\\'document_id\\': \\'num-0\\'}\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 2\\nContent: . \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses, to determine whether the issue has been\\nresolved:\\n7\\n. \\nReview events within the namespace for diagnostic information relating to pod failures:\\n7.7.3. Inspecting pod and container logs\\nYou can inspect pod and container logs for warnings and error messages related to explicit pod failures.\\nDepending on policy and exit code, pod and container logs remain available after pods have been\\nterminated.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nProcedure\\n1\\n. \\nQuery logs for a specific pod:\\n2\\n. \\nQuery logs for a specific container within a pod:\\n$ oc get pods\\n$ oc status\\n$ skopeo inspect docker://&lt;image_reference&gt;\\n$ oc edit deployment/my-deployment\\n$ oc get pods -w\\n$ oc get events\\n$ oc logs &lt;pod_name&gt;\\nOpenShift Container Platform 4.11 Support\\n118\\nLogs retrieved using the preceding \\noc logs\\n commands are composed of messages sent to\\nstdout within pods or containers.\\n3\\n. \\nInspect logs contained in \\n/var/log/\\n within a pod.\\na\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a pod:\\nExample output\\nb\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a pod:\\nExample output\\nc\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a specific container:\\nd\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a specific container:\\n$ oc logs &lt;pod_name&gt; -c &lt;container_name&gt;\\n$ oc exec &lt;pod_name&gt;  -- ls -alh /var/log\\ntotal 124K\\ndrwxr-xr-x. 1 root root   33 Aug 11 11:23 .\\n\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 3\\nContent:  the \\nopenshift-sdn\\n namespace:\\nc\\n. \\nReview logs relating to failed OpenShift Container Platform SDN pods in the \\nopenshift-\\nsdn\\n namespace:\\n7\\n. \\nDetermine cluster network configuration status.\\na\\n. \\nReview whether the cluster’s network configuration exists:\\nb\\n. \\nIf the installer failed to create the network configuration, generate the Kubernetes\\nmanifests again and review message output:\\nc\\n. \\nReview the pod status in the \\nopenshift-network-operator\\n namespace to determine\\nwhether the Cluster Network Operator (CNO) is running:\\nd\\n. \\nGather network Operator pod logs from the \\nopenshift-network-operator\\n namespace:\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\n$ oc get nodes\\n$ oc describe node &lt;master_node&gt;\\n$ oc get daemonsets -n openshift-sdn\\n$ oc get pods -n openshift-sdn\\n$ oc logs &lt;sdn_pod&gt; -n openshift-sdn\\n$ oc get network.config.openshift.io cluster -o yaml\\n$ ./openshift-install create manifests\\n$ oc get pods -n openshift-network-operator\\n$ oc logs pod/&lt;network_operator_pod_name&gt; -n openshift-network-operator\\nOpenShift Container Platform 4.11 Support\\n72\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nRetrieve the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n&lt;master-node&gt;.\\n&lt;cluster_name&gt;.&lt;base_domain&gt;\\n with appropriate values:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS (RHCOS) are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nBefore attempting to collect diagnostic data over SSH, review whether the\\ndata collected by running \\noc adm must gather\\n and other \\noc\\n commands is\\nsufficient instead. However, if the OpenShift Container Platform API is not\\navailable, or the kubelet is not properly functioning on the target node, \\noc\\noperations will be impacted. In such situations, it is possible to access nodes\\nusing \\nssh core@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt;\\n.\\n9\\n\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 4\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --role=master -u crio\\n$ oc adm node-logs &lt;node_name&gt; -u crio\\n$ ssh core@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt; journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation (\\ncrio\\n) is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/&lt;node_name&gt;\\nbecause the container runtime instance (\\ncrio\\n) is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'Result 5\\nContent: \\n  Normal   Pulling         8s (x3 over 47s)   kubelet            Pulling image \"quay.io/example-\\norg/example-catalog:v1\"\\n  Warning  Failed          8s (x3 over 47s)   kubelet            Failed to pull image\\n \\n\"quay.io/example-org/example-catalog:v1\": rpc error: code = Unknown desc = reading\\n \\nmanifest v1 in quay.io/example-org/example-catalog: unauthorized: access to the requested\\n \\nresource is not authorized\\n  Warning  Failed          8s (x3 over 47s)   kubelet            Error: ErrImagePull\\n$ oc get clusteroperators\\n$ oc get pod -n &lt;operator_namespace&gt;\\nOpenShift Container Platform 4.11 Support\\n104\\n3\\n. \\nOutput a detailed Operator pod summary:\\n4\\n. \\nIf an Operator issue is node-specific, query Operator container status on that node.\\na\\n. \\nStart a debug pod for the node:\\nb\\n. \\nSet \\n/host\\n as the root directory within the debug shell. The debug pod mounts the host’s\\nroot file system in \\n/host\\n within the pod. By changing the root directory to \\n/host\\n, you can run\\nbinaries contained in the host’s executable paths:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS (RHCOS) are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nHowever, if the OpenShift Container Platform API is not available, or the\\nkubelet is not properly functioning on the target node, \\noc\\n operations will be\\nimpacted. In such situations, it is possible to access nodes using \\nssh\\n \\ncore@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt;\\n instead.\\nc\\n. \\nList details about the node’s containers, including state and associated pod IDs:\\nd\\n. \\nList information about a specific Operator container on the node. The following example\\nlists information about the \\nnetwork-operator\\n container:\\ne\\n. \\nExit from the debug shell.\\n7.6.5. Gathering Operator logs\\nIf you experience Operator issues, you can gather detailed diagnostic information from Operator pod\\nlogs.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nYou have the fully qualified domain names of\\nMetadata: {\\'document_id\\': \\'num-0\\'}\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'END of knowledge_search tool results.\\n'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The above results were retrieved to help answer the user\\'s query: \"Kubernetes pod failure unknown error during startup missing dependencies configuration errors permission issues\". Use them as supporting information only in answering this query.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon \u001b[0m\u001b[32m<\u001b[0m\u001b[32mnode_name\u001b[0m\u001b[32m>\\n$ oc adm drain <node_name> --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m status, whereas other\\n.. for pod in $\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl pods -q\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do if \u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m \"$\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\" != \"\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'document_id\\': \\'num-0\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 2\\nContent: . \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses, to determine whether the issue has been\\nresolved:\\n7\\n. \\nReview events within the namespace for diagnostic information relating to pod failures:\\n7.7.3. Inspecting pod and container logs\\nYou can inspect pod and container logs for warnings and error messages related to explicit pod failures.\\nDepending on policy and exit code, pod and container logs remain available after pods have been\\nterminated.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProcedure\\n1\\n. \\nQuery logs for a specific pod:\\n2\\n. \\nQuery logs for a specific container within a pod:\\n$ oc get pods\\n$ oc status\\n$ skopeo inspect docker://<image_reference>\\n$ oc edit deployment/my-deployment\\n$ oc get pods -w\\n$ oc get events\\n$ oc logs <pod_name>\\nOpenShift Container Platform 4.11 Support\\n118\\nLogs retrieved using the preceding \\noc logs\\n commands are composed of messages sent to\\nstdout within pods or containers.\\n3\\n. \\nInspect logs contained in \\n/var/log/\\n within a pod.\\na\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a pod:\\nExample output\\nb\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a pod:\\nExample output\\nc\\n. \\nList log files and subdirectories contained in \\n/var/log\\n within a specific container:\\nd\\n. \\nQuery a specific log file contained in \\n/var/log\\n within a specific container:\\n$ oc logs <pod_name> -c <container_name>\\n$ oc exec <pod_name>  -- ls -alh /var/log\\ntotal 124K\\ndrwxr-xr-x. 1 root root   33 Aug 11 11:23 .\\n\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 3\\nContent:  the \\nopenshift-sdn\\n namespace:\\nc\\n. \\nReview logs relating to failed OpenShift Container Platform SDN pods in the \\nopenshift-\\nsdn\\n namespace:\\n7\\n. \\nDetermine cluster network configuration status.\\na\\n. \\nReview whether the cluster’s network configuration exists:\\nb\\n. \\nIf the installer failed to create the network configuration, generate the Kubernetes\\nmanifests again and review message output:\\nc\\n. \\nReview the pod status in the \\nopenshift-network-operator\\n namespace to determine\\nwhether the Cluster Network Operator \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCNO\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is running:\\nd\\n. \\nGather network Operator pod logs from the \\nopenshift-network-operator\\n namespace:\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\n$ oc get nodes\\n$ oc describe node <master_node>\\n$ oc get daemonsets -n openshift-sdn\\n$ oc get pods -n openshift-sdn\\n$ oc logs <sdn_pod> -n openshift-sdn\\n$ oc get network.config.openshift.io cluster -o yaml\\n$ ./openshift-install create manifests\\n$ oc get pods -n openshift-network-operator\\n$ oc logs pod/<network_operator_pod_name> -n openshift-network-operator\\nOpenShift Container Platform 4.11 Support\\n72\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nRetrieve the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n<master-node>.\\n<cluster_name>.<base_domain>\\n with appropriate values:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRHCOS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nBefore attempting to collect diagnostic data over SSH, review whether the\\ndata collected by running \\noc adm must gather\\n and other \\noc\\n commands is\\nsufficient instead. However, if the OpenShift Container Platform API is not\\navailable, or the kubelet is not properly functioning on the target node, \\noc\\noperations will be impacted. In such situations, it is possible to access nodes\\nusing \\nssh core@<node>.<cluster_name>.<base_domain>\\n.\\n9\\n\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 4\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --\u001b[0m\u001b[32mrole\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmaster\u001b[0m\u001b[32m -u crio\\n$ oc adm node-logs <node_name> -u crio\\n$ ssh core@<node>.<cluster_name>.<base_domain> journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/<node_name>\\nbecause the container runtime instance \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'Result 5\\nContent: \\n  Normal   Pulling         8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Pulling image \"quay.io/example-\\norg/example-catalog:v1\"\\n  Warning  Failed          8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Failed to pull image\\n \\n\"quay.io/example-org/example-catalog:v1\": rpc error: code = Unknown desc = reading\\n \\nmanifest v1 in quay.io/example-org/example-catalog: unauthorized: access to the requested\\n \\nresource is not authorized\\n  Warning  Failed          8s \u001b[0m\u001b[32m(\u001b[0m\u001b[32mx3 over 47s\u001b[0m\u001b[32m)\u001b[0m\u001b[32m   kubelet            Error: ErrImagePull\\n$ oc get clusteroperators\\n$ oc get pod -n <operator_namespace>\\nOpenShift Container Platform 4.11 Support\\n104\\n3\\n. \\nOutput a detailed Operator pod summary:\\n4\\n. \\nIf an Operator issue is node-specific, query Operator container status on that node.\\na\\n. \\nStart a debug pod for the node:\\nb\\n. \\nSet \\n/host\\n as the root directory within the debug shell. The debug pod mounts the host’s\\nroot file system in \\n/host\\n within the pod. By changing the root directory to \\n/host\\n, you can run\\nbinaries contained in the host’s executable paths:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRHCOS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nHowever, if the OpenShift Container Platform API is not available, or the\\nkubelet is not properly functioning on the target node, \\noc\\n operations will be\\nimpacted. In such situations, it is possible to access nodes using \\nssh\\n \\ncore@<node>.<cluster_name>.<base_domain\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\n instead.\\nc\\n. \\nList details about the node’s containers, including state and associated pod IDs:\\nd\\n. \\nList information about a specific Operator container on the node. The following example\\nlists information about the \\nnetwork-operator\\n container:\\ne\\n. \\nExit from the debug shell.\\n7.6.5. Gathering Operator logs\\nIf you experience Operator issues, you can gather detailed diagnostic information from Operator pod\\nlogs.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYour API service is still functional.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nYou have the fully qualified domain names of\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'document_id\\': \\'num-0\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'END of knowledge_search tool results.\\n'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'The above results were retrieved to help answer the user\\'s query: \"Kubernetes pod failure unknown error during startup missing dependencies configuration errors permission issues\". Use them as supporting information only in answering this query.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/b9f4bcbd-1d38-4aee-99ad-c2ea23ad1126/session/04a77331-70a3-4013-bbee-3a7bc7044962/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m<think>\n",
      "Okay, let's see. The user is asking for a summary of steps to resolve the Kubernetes pod failure with an unknown error during startup, mentioning missing dependencies, configuration errors, or permission issues.\n",
      "\n",
      "First, I need to go through the knowledge_search results provided. The results include various OpenShift and Kubernetes troubleshooting steps. Let me parse each result to find relevant information.\n",
      "\n",
      "Result 1 talks about draining nodes, stopping kubelet and containers, and cleaning up storage. That seems related to node issues but maybe not directly the pod's configuration.\n",
      "\n",
      "Result 2 mentions checking pod logs, inspecting base images, and reviewing events. This is directly relevant because the user's issue could be due to image or configuration problems. The steps here include using 'oc logs' and 'oc get events' to diagnose.\n",
      "\n",
      "Result 3 discusses checking SDN pods and network configurations. If the pod has network issues, that could cause startup errors. However, the user's error message doesn't mention networking specifically, so maybe this is less relevant unless dependencies are network-related.\n",
      "\n",
      "Result 4 is about CRI-O storage issues leading to pod failures. The \"can't stat lower layer\" error is mentioned, which relates to storage. If the user's error is due to missing dependencies, storage issues could be a cause. The steps here involve draining the node, stopping services, and cleaning up storage.\n",
      "\n",
      "Result 5 shows an example of image pull errors due to authorization. The user's error mentions \"missing dependencies,\" which could include image pull issues. Checking image references and permissions here is important.\n",
      "\n",
      "Putting this together, the main steps would involve checking pod logs, verifying the container image is correct and accessible, ensuring proper permissions, and looking at events for more clues. If storage is an issue, cleaning up CRI-O storage might help. Also, inspecting the deployment configuration for errors is key.\n",
      "\n",
      "I need to condense these steps into 1-2 sentences. Focus on checking logs, image references, permissions, and events. Maybe mention redeploying after fixes. Also, if storage is a problem, the cleanup steps from result 4 could be included briefly.\n",
      "</think>\n",
      "\n",
      "To resolve the pod failure, first check the pod's logs (`oc logs <pod_name>`) and events (`oc get events -n llama-serve`) to identify specific issues with the container image, configuration, or permissions. If missing dependencies or image pull errors occur, verify the image reference in the deployment, ensure the image is accessible (e.g., correct registry credentials), and re-deploy. For storage-related issues (e.g., \"can’t stat lower layer\"), drain the node, stop `crio`/`kubelet`, and clean up CRI-O storage as described in OpenShift troubleshooting guides.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n",
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🛠️ Tool call Generated:\n",
      "\u001b[35mTool call: slack_post_message, Arguments: {'channel_id': '#demos', 'text': \"To resolve the pod failure in `llama-serve`:\\n1. Check logs/events: `oc logs slack-test -n llama-serve` and `oc get events -n llama-serve`.\\n2. Fix image/config issues (e.g., verify image pull permissions, correct registry credentials).\\n3. For storage errors (e.g., 'can’t stat lower layer'), drain the node, stop `crio`/`kubelet`, and clean CRI-O storage per OpenShift guides.\"}\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":{\"warnings\":[\"missing_charset\"]}}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"warnings\":\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"missing_charset\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m<think>\n",
      "Okay, the user tried to send a message to the Slack #demos channel using the slack_post_message tool, but it failed with an \"invalid_auth\" error. Hmm, that usually means the authentication token is missing or incorrect. Let me check the tool's parameters. The function requires channel_id and text. The user provided the channel_id as \"#demos\" and the text. But maybe the channel_id should be just \"demos\" without the # symbol? Wait, the Slack API typically uses channel IDs like \"C1234567890\" or names without the #. Maybe the tool expects the channel name without the #. Let me see the tool's description again. The slack_post_message function's parameters for channel_id say \"The ID of the channel to post to.\" Oh, right, the ID is usually the numeric ID, not the name with a #. So using \"#demos\" is incorrect. The correct channel ID would be something like \"C0123456789\". The user probably used the channel name with the #, which isn't valid for the API. Also, the error mentions \"invalid_auth\", which could be related to the token not having access to that channel or the token itself being invalid. But the main issue here is likely the channel_id format. So I should inform the user that the channel_id should be the numeric ID, not the name with a #, and suggest they retrieve the correct channel ID using the Slack API or UI. Additionally, check if the authentication token is correctly set up.\n",
      "</think>\n",
      "\n",
      "The Slack message failed to send due to an authentication error (`invalid_auth`). This typically occurs when:\n",
      "\n",
      "1. **Channel ID format is incorrect**: Slack channel IDs should be the numeric ID (e.g., `C1234567890`), not the name with a `#` (e.g., `#demos`). Use the Slack UI or API to find the correct channel ID.\n",
      "2. **Authentication token is missing/invalid**: Ensure the Slack API token used by the tool has `chat:write` permissions and is valid for the workspace.\n",
      "\n",
      "**Fix**: Retrieve the correct channel ID for `#demos` (e.g., via Slack's \"Invite People and Channels\" dialog or API), then retry with the numeric ID. Example:\n",
      "```tool_call\n",
      "{\"name\": \"slack_post_message\", \"arguments\": {\"channel_id\": \"C0123456789\", \"text\": \"...\"}}\n",
      "```\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model=model_id, # replace this with your choice of model\n",
    "    instructions = model_prompt , # update system prompt based on the model you are using\n",
    "    tools=[dict(\n",
    "            name=\"builtin::rag\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [vector_db_id],  # list of IDs of document collections to consider during retrieval\n",
    "            },\n",
    "        ),\"mcp::openshift\", \"mcp::slack\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params=sampling_params\n",
    ")\n",
    "\n",
    "user_prompts = [\"View the logs for pod slack-test in the llama-serve OpenShift namespace. Categorize it as normal or error.\",\n",
    "                \"Search for solutions on this error and provide a summary of the steps to take in just 1-2 sentences.\",\n",
    "                \"Send a message with the summarization to the demos channel on Slack with a tool call\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_Slack_demo\")\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream,\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a105531",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Lets step through the output to further understands whats happening in this Agentic demo.\n",
    "\n",
    "1. First the LLM sends off a tool call to the `pods_log` tool configured with the OpenShift MCP server, to fetch the logs for the pod specified from the OpenShift cluster.\n",
    "2. The tool successfully retrieves the logs for the pod.\n",
    "3. The LLM recieves the response from the tool call, which are the pod logs, along with the original query and using its own knowledge tries to categorize it as 'Normal or 'Error'.\n",
    "4. Next, the LLM sends a tool call to the RAG tool, to query the vector DB on the documents for the error from the pod logs and look for a solution to resolve the error from the document.\n",
    "5. The LLM recieves the response from the tool call, and summarizes the information it retreived from the document.\n",
    "6. Finally, the LLM sends the summarization as a message on Slack using the `slack_post_message` tool call configured with the Slack MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6c84d",
   "metadata": {},
   "source": [
    "## Defining our Agent - ReAct\n",
    "\n",
    "Now that we've shown that we can successfully accomplish this multi-step multi-tool task using prompt chaining, let's see if we can give our agent a bit more autonomy to perform the same task but with a single prompt instead of a chian. To do this, we will instantiate a ReAct agent (which is included in the llama stack python client by default). The ReAct agent is a variant of the simple agent but with the ability to loop through \"Reason then Act\" iterations, thinking through the problem and then using tools until it determines that it's task has been completed successfully.\n",
    "\n",
    "Unlike prompt chaining which follows fixed steps, ReAct dynamically breaks down tasks and adapts its approach based on the results of each step. This makes it more flexible and capable of handling complex, real-world queries effectively.\n",
    "\n",
    "Below you will see the slight differences in the agent definition and the prompt used to accomplish our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a606a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aslack \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aopenshift \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=builtin%3A%3Arag \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aslack \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=mcp%3A%3Aopenshift \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://llamastack:8321/v1/tools?toolgroup_id=builtin%3A%3Arag \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/773687cb-d023-41e0-b692-801e0adb5789/session \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/773687cb-d023-41e0-b692-801e0adb5789/session/ac0e47c8-06a8-4678-8f89-ddcf59073242/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\u001b[34mProcessing user query: View the logs for pod slack-test in the llama-serve OpenShift namespace. Categorize it as normal or error, \n",
      "                search for solutions on this error and provide a summary of the steps to take in just 1-2 sentences.\n",
      "                Send a message with the summarization to the demos channel on Slack. Let me know when you've sent the message.\n",
      "                \u001b[0m\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/773687cb-d023-41e0-b692-801e0adb5789/session/ac0e47c8-06a8-4678-8f89-ddcf59073242/turn/9d422617-fc92-4893-8640-dbbf9eb0fe19/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/773687cb-d023-41e0-b692-801e0adb5789/session/ac0e47c8-06a8-4678-8f89-ddcf59073242/turn/9d422617-fc92-4893-8640-dbbf9eb0fe19/resume \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/tool-runtime/invoke \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://llamastack:8321/v1/agents/773687cb-d023-41e0-b692-801e0adb5789/session/ac0e47c8-06a8-4678-8f89-ddcf59073242/turn/9d422617-fc92-4893-8640-dbbf9eb0fe19/resume \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 1: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"I will proceed step by step: first, I will get the logs for the pod 'slack-test' in the 'llama-serve' namespace. Then, I will analyze the logs to categorize them as normal or error. After that, I will search for solutions related to any errors found. Finally, I will summarize the steps to take and send a message to the 'demos' channel on Slack.\", \"action\": {\"tool_name\": \"pods_log\", \"tool_params\": [{\"name\": \"name\", \"value\": \"slack-test\"}, {\"name\": \"namespace\", \"value\": \"llama-serve\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 2: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 3: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"The logs indicate an error with the container startup. I will categorize this as an error and proceed to search for solutions related to the 'Unknown Error' and 'Container failed during startup' issues.\", \"action\": {\"tool_name\": \"knowledge_search\", \"tool_params\": [{\"name\": \"query\", \"value\": \"Kubernetes container startup error unknown error missing dependencies configuration errors\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 4: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon &lt;node_name&gt;\\n$ oc adm drain &lt;node_name&gt; --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability (GA) status, whereas other\\n.. for pod in $(crictl pods -q); do if [[ \"$(crictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network)\" != \"\\nMetadata: {\\'document_id\\': \\'num-0\\'}\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 2\\nContent:  the \\nopenshift-sdn\\n namespace:\\nc\\n. \\nReview logs relating to failed OpenShift Container Platform SDN pods in the \\nopenshift-\\nsdn\\n namespace:\\n7\\n. \\nDetermine cluster network configuration status.\\na\\n. \\nReview whether the cluster’s network configuration exists:\\nb\\n. \\nIf the installer failed to create the network configuration, generate the Kubernetes\\nmanifests again and review message output:\\nc\\n. \\nReview the pod status in the \\nopenshift-network-operator\\n namespace to determine\\nwhether the Cluster Network Operator (CNO) is running:\\nd\\n. \\nGather network Operator pod logs from the \\nopenshift-network-operator\\n namespace:\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\n$ oc get nodes\\n$ oc describe node &lt;master_node&gt;\\n$ oc get daemonsets -n openshift-sdn\\n$ oc get pods -n openshift-sdn\\n$ oc logs &lt;sdn_pod&gt; -n openshift-sdn\\n$ oc get network.config.openshift.io cluster -o yaml\\n$ ./openshift-install create manifests\\n$ oc get pods -n openshift-network-operator\\n$ oc logs pod/&lt;network_operator_pod_name&gt; -n openshift-network-operator\\nOpenShift Container Platform 4.11 Support\\n72\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nRetrieve the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n&lt;master-node&gt;.\\n&lt;cluster_name&gt;.&lt;base_domain&gt;\\n with appropriate values:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS (RHCOS) are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nBefore attempting to collect diagnostic data over SSH, review whether the\\ndata collected by running \\noc adm must gather\\n and other \\noc\\n commands is\\nsufficient instead. However, if the OpenShift Container Platform API is not\\navailable, or the kubelet is not properly functioning on the target node, \\noc\\noperations will be impacted. In such situations, it is possible to access nodes\\nusing \\nssh core@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt;\\n.\\n9\\n\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 3\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --role=master -u crio\\n$ oc adm node-logs &lt;node_name&gt; -u crio\\n$ ssh core@&lt;node&gt;.&lt;cluster_name&gt;.&lt;base_domain&gt; journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation (\\ncrio\\n) is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/&lt;node_name&gt;\\nbecause the container runtime instance (\\ncrio\\n) is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 4\\nContent:  control plane node and\\nthe nodes have joined the cluster, the errors should stop.\\n3\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nMonitor the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n&lt;master-node&gt;.\\n&lt;cluster_name&gt;.&lt;base_domain&gt;\\n with appropriate values:\\n$ tail -f ~/&lt;installation_directory&gt;/.openshift_install.log\\n$ ssh core@&lt;bootstrap_fqdn&gt; journalctl -b -f -u bootkube.service\\n$ oc adm node-logs --role=master -u kubelet\\nOpenShift Container Platform 4.11 Support\\n68\\n1\\n4\\n. \\nMonitor \\ncrio.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node CRI-O container runtime activity.\\na\\n. \\nMonitor the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n&lt;master-node&gt;.\\n&lt;cluster_name&gt;.&lt;base_domain&gt;\\n with appropriate values:\\n7.1.7. Gathering bootstrap node diagnostic data\\nWhen experiencing bootstrap-related issues, you can gather \\nbootkube.service\\n \\njournald\\n unit logs and\\ncontainer logs from the bootstrap node.\\nPrerequisites\\nYou have SSH access to your bootstrap node.\\nYou have the fully qualified domain name of the bootstrap node.\\nIf you are hosting Ignition configuration files by using an HTTP server, you must have the HTTP\\nserver’s fully qualified domain name and the port number. You must also have SSH access to\\nthe HTTP host.\\nProcedure\\n1\\n. \\nIf you have access to the bootstrap node’s console, monitor the console until the node reaches\\nthe login prompt.\\n2\\n. \\nVerify the Ignition file configuration.\\nIf you are hosting Ignition configuration files by using an HTTP server.\\na\\n. \\nVerify the bootstrap node Ignition file URL. Replace \\n&lt;http_server_fqdn&gt;\\n with HTTP\\nserver’s fully qualified domain name:\\nThe \\n-I\\n option returns the header only. If the Ignition file is available on the specified\\nURL, the command returns \\n200 OK\\n status. If it is not available, the command\\nreturns \\n404 file not found\\n.\\nb\\n. \\nTo verify that the Ignition\\nMetadata: {'document_id': 'num-0'}\\n\"</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Result 5\\nContent: .\\nErrInvalidImage\\nName\\nThe specified image name was invalid.\\nErrImageInspec\\nt\\nImage inspection did not succeed.\\nErrImageNeverP\\null\\nPullPolicy\\n is set to \\nNeverPullImage\\n and the target image is not present locally on\\nthe host.\\nErrRegistryUna\\nvailable\\nWhen attempting to retrieve an image from a registry, an HTTP error was encountered.\\nErrContainerNot\\nFound\\nThe specified container is either not present or not managed by the kubelet, within the\\ndeclared pod.\\nOpenShift Container Platform 4.11 Support\\n116\\nErrRunInitConta\\niner\\nContainer initialization failed.\\nErrRunContaine\\nr\\nNone of the pod’s containers started successfully.\\nErrKillContainer\\nNone of the pod’s containers were killed successfully.\\nErrCrashLoopB\\nackOff\\nA container has terminated. The kubelet will not attempt to restart it.\\nErrVerifyNonRo\\not\\nA container or image attempted to run with root privileges.\\nErrCreatePodSa\\nndbox\\nPod sandbox creation did not succeed.\\nErrConfigPodSa\\nndbox\\nPod sandbox configuration was not obtained.\\nErrKillPodSand\\nbox\\nA pod sandbox did not stop successfully.\\nErrSetupNetwor\\nk\\nNetwork initialization failed.\\nErrTeardownNet\\nwork\\nNetwork termination failed.\\nPod error state\\nDescription\\n7.7.2. Reviewing pod status\\nYou can query pod status and error states. You can also query a pod’s associated deployment\\nconfiguration and review base image availability.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI (\\noc\\n).\\nskopeo\\n is installed.\\nProcedure\\n1\\n. \\nSwitch into a project:\\n$ oc project &lt;project_name&gt;\\nCHAPTER 7. TROUBLESHOOTING\\n117\\n2\\n. \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses,\\nMetadata: {'document_id': 'num-0'}\\n\"</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'END of knowledge_search tool results.\\n'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextContentItem</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The above results were retrieved to help answer the user\\'s query: \"Kubernetes container startup error unknown error missing dependencies configuration errors\". Use them as supporting information only in answering this query.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'Result 1\\nContent:  period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal relies on the networking plugin pods, which are in\\nthe \\nHostNetwork\\n.\\ncan\\'t stat lower layer ...  because it does not exist.  Going through storage to recreate the\\n \\nmissing symlinks.\\n$ oc adm cordon \u001b[0m\u001b[32m<\u001b[0m\u001b[32mnode_name\u001b[0m\u001b[32m>\\n$ oc adm drain <node_name> --ignore-daemonsets --delete-emptydir-data\\n$ ssh core@node1.example.com\\n$ sudo -i\\n# systemctl stop kubelet\\nOpenShift Container Platform 4.11 Support\\n90\\nb\\n. \\nStop all other pods:\\n6\\n. \\nManually stop the crio services:\\n7\\n. \\nAfter you run those commands, you can completely wipe the ephemeral storage:\\n8\\n. \\nStart the crio and kubelet service:\\n9\\n. \\nYou will know if the clean up worked if the crio and kubelet services are started, and the node is\\nin the \\nReady\\n status:\\nExample output\\n10\\n. \\nMark the node schedulable. You will know that the scheduling is enabled when \\nSchedulingDisabled\\n is no longer in status:\\nExample output\\n7.4. TROUBLESHOOTING OPERATING SYSTEM ISSUES\\nOpenShift Container Platform runs on RHCOS. You can follow these procedures to troubleshoot\\nproblems related to the operating system.\\n7.4.1. Investigating kernel crashes\\nThe \\nkdump\\n service, included in the \\nkexec-tools\\n package, provides a crash-dumping mechanism. You\\ncan use this service to save the contents of a system’s memory for later analysis.\\nThe \\nx86_64\\n architecture supports kdump in General Availability \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m status, whereas other\\n.. for pod in $\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl pods -q\u001b[0m\u001b[32m)\u001b[0m\u001b[32m; do if \u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m \"$\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcrictl inspectp $pod | jq -r\\n \\n.status.linux.namespaces.options.network\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\" != \"\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'document_id\\': \\'num-0\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 2\\nContent:  the \\nopenshift-sdn\\n namespace:\\nc\\n. \\nReview logs relating to failed OpenShift Container Platform SDN pods in the \\nopenshift-\\nsdn\\n namespace:\\n7\\n. \\nDetermine cluster network configuration status.\\na\\n. \\nReview whether the cluster’s network configuration exists:\\nb\\n. \\nIf the installer failed to create the network configuration, generate the Kubernetes\\nmanifests again and review message output:\\nc\\n. \\nReview the pod status in the \\nopenshift-network-operator\\n namespace to determine\\nwhether the Cluster Network Operator \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCNO\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is running:\\nd\\n. \\nGather network Operator pod logs from the \\nopenshift-network-operator\\n namespace:\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\n$ oc get nodes\\n$ oc describe node <master_node>\\n$ oc get daemonsets -n openshift-sdn\\n$ oc get pods -n openshift-sdn\\n$ oc logs <sdn_pod> -n openshift-sdn\\n$ oc get network.config.openshift.io cluster -o yaml\\n$ ./openshift-install create manifests\\n$ oc get pods -n openshift-network-operator\\n$ oc logs pod/<network_operator_pod_name> -n openshift-network-operator\\nOpenShift Container Platform 4.11 Support\\n72\\n8\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nRetrieve the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n<master-node>.\\n<cluster_name>.<base_domain>\\n with appropriate values:\\nNOTE\\nOpenShift Container Platform 4.11 cluster nodes running Red Hat Enterprise\\nLinux CoreOS \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRHCOS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are immutable and rely on Operators to apply\\ncluster changes. Accessing cluster nodes by using SSH is not recommended.\\nBefore attempting to collect diagnostic data over SSH, review whether the\\ndata collected by running \\noc adm must gather\\n and other \\noc\\n commands is\\nsufficient instead. However, if the OpenShift Container Platform API is not\\navailable, or the kubelet is not properly functioning on the target node, \\noc\\noperations will be impacted. In such situations, it is possible to access nodes\\nusing \\nssh core@<node>.<cluster_name>.<base_domain>\\n.\\n9\\n\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 3\\nContent:  the CRI-O ephemeral storage if you experience the following issues:\\nA node cannot run on any pods and this error appears:\\nYou cannot create a new container on a working node and the “can’t stat lower layer” error\\nappears:\\n$ oc adm node-logs --\u001b[0m\u001b[32mrole\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmaster\u001b[0m\u001b[32m -u crio\\n$ oc adm node-logs <node_name> -u crio\\n$ ssh core@<node>.<cluster_name>.<base_domain> journalctl -b -f -u crio.service\\nFailed to create pod sandbox: rpc error: code = Unknown desc = failed to mount container\\n \\nXXX: error recreating the missing symlinks: error reading name of symlink for XXX: open\\n \\n/var/lib/containers/storage/overlay/XXX/link: no such file or directory\\nCHAPTER 7. TROUBLESHOOTING\\n89\\nYour node is in the \\nNotReady\\n state after a cluster upgrade or if you attempt to reboot it.\\nThe container runtime implementation \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working properly.\\nYou are unable to start a debug shell on the node using \\noc debug node/<node_name>\\nbecause the container runtime instance \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\ncrio\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m is not working.\\nFollow this process to completely wipe the CRI-O storage and resolve the errors.\\nPrerequisites:\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nProcedure\\n1\\n. \\nUse \\ncordon\\n on the node. This is to avoid any workload getting scheduled if the node gets into\\nthe \\nReady\\n status. You will know that scheduling is disabled when \\nSchedulingDisabled\\n is in your\\nStatus section:\\n2\\n. \\nDrain the node as the cluster-admin user:\\nNOTE\\nThe \\nterminationGracePeriodSeconds\\n attribute of a pod or pod template\\ncontrols the graceful termination period. This attribute defaults at 30 seconds,\\nbut can be customized for each application as necessary. If set to more than 90\\nseconds, the pod might be marked as \\nSIGKILLed\\n and fail to terminate\\nsuccessfully.\\n3\\n. \\nWhen the node returns, connect back to the node via SSH or Console. Then connect to the root\\nuser:\\n4\\n. \\nManually stop the kubelet:\\n5\\n. \\nStop the containers and pods:\\na\\n. \\nUse the following command to stop the pods that are not in the \\nHostNetwork\\n. They must\\nbe removed first because their removal\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 4\\nContent:  control plane node and\\nthe nodes have joined the cluster, the errors should stop.\\n3\\n. \\nMonitor \\nkubelet.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node agent activity.\\na\\n. \\nMonitor the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n<master-node>.\\n<cluster_name>.<base_domain>\\n with appropriate values:\\n$ tail -f ~/<installation_directory>/.openshift_install.log\\n$ ssh core@<bootstrap_fqdn> journalctl -b -f -u bootkube.service\\n$ oc adm node-logs --\u001b[0m\u001b[32mrole\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmaster\u001b[0m\u001b[32m -u kubelet\\nOpenShift Container Platform 4.11 Support\\n68\\n1\\n4\\n. \\nMonitor \\ncrio.service\\n journald unit logs on control plane nodes, after they have booted. This\\nprovides visibility into control plane node CRI-O container runtime activity.\\na\\n. \\nMonitor the logs using \\noc\\n:\\nb\\n. \\nIf the API is not functional, review the logs using SSH instead. Replace \\n<master-node>.\\n<cluster_name>.<base_domain>\\n with appropriate values:\\n7.1.7. Gathering bootstrap node diagnostic data\\nWhen experiencing bootstrap-related issues, you can gather \\nbootkube.service\\n \\njournald\\n unit logs and\\ncontainer logs from the bootstrap node.\\nPrerequisites\\nYou have SSH access to your bootstrap node.\\nYou have the fully qualified domain name of the bootstrap node.\\nIf you are hosting Ignition configuration files by using an HTTP server, you must have the HTTP\\nserver’s fully qualified domain name and the port number. You must also have SSH access to\\nthe HTTP host.\\nProcedure\\n1\\n. \\nIf you have access to the bootstrap node’s console, monitor the console until the node reaches\\nthe login prompt.\\n2\\n. \\nVerify the Ignition file configuration.\\nIf you are hosting Ignition configuration files by using an HTTP server.\\na\\n. \\nVerify the bootstrap node Ignition file URL. Replace \\n<http_server_fqdn>\\n with HTTP\\nserver’s fully qualified domain name:\\nThe \\n-I\\n option returns the header only. If the Ignition file is available on the specified\\nURL, the command returns \\n200 OK\\n status. If it is not available, the command\\nreturns \\n404 file not found\\n.\\nb\\n. \\nTo verify that the Ignition\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1;39m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m\u001b[39m=\u001b[0m\u001b[32m\"Result\u001b[0m\u001b[32m 5\\nContent: .\\nErrInvalidImage\\nName\\nThe specified image name was invalid.\\nErrImageInspec\\nt\\nImage inspection did not succeed.\\nErrImageNeverP\\null\\nPullPolicy\\n is set to \\nNeverPullImage\\n and the target image is not present locally on\\nthe host.\\nErrRegistryUna\\nvailable\\nWhen attempting to retrieve an image from a registry, an HTTP error was encountered.\\nErrContainerNot\\nFound\\nThe specified container is either not present or not managed by the kubelet, within the\\ndeclared pod.\\nOpenShift Container Platform 4.11 Support\\n116\\nErrRunInitConta\\niner\\nContainer initialization failed.\\nErrRunContaine\\nr\\nNone of the pod’s containers started successfully.\\nErrKillContainer\\nNone of the pod’s containers were killed successfully.\\nErrCrashLoopB\\nackOff\\nA container has terminated. The kubelet will not attempt to restart it.\\nErrVerifyNonRo\\not\\nA container or image attempted to run with root privileges.\\nErrCreatePodSa\\nndbox\\nPod sandbox creation did not succeed.\\nErrConfigPodSa\\nndbox\\nPod sandbox configuration was not obtained.\\nErrKillPodSand\\nbox\\nA pod sandbox did not stop successfully.\\nErrSetupNetwor\\nk\\nNetwork initialization failed.\\nErrTeardownNet\\nwork\\nNetwork termination failed.\\nPod error state\\nDescription\\n7.7.2. Reviewing pod status\\nYou can query pod status and error states. You can also query a pod’s associated deployment\\nconfiguration and review base image availability.\\nPrerequisites\\nYou have access to the cluster as a user with the \\ncluster-admin\\n role.\\nYou have installed the OpenShift CLI \u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\noc\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\nskopeo\\n is installed.\\nProcedure\\n1\\n. \\nSwitch into a project:\\n$ oc project <project_name\u001b[0m\u001b[32m>\u001b[0m\u001b[32m\\nCHAPTER 7. TROUBLESHOOTING\\n117\\n2\\n. \\nList pods running within the namespace, as well as pod status, error states, restarts, and age:\\n3\\n. \\nDetermine whether the namespace is managed by a deployment configuration:\\nIf the namespace is managed by a deployment configuration, the output includes the\\ndeployment configuration name and a base image reference.\\n4\\n. \\nInspect the base image referenced in the preceding command’s output:\\n5\\n. \\nIf the base image reference is not correct, update the reference in the deployment\\nconfiguration:\\n6\\n. \\nWhen deployment configuration changes on exit, the configuration will automatically redeploy.\\nWatch pod status as the deployment progresses,\\nMetadata: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'document_id': 'num-0'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\"\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'END of knowledge_search tool results.\\n'\u001b[0m, \u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1;35mTextContentItem\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtext\u001b[0m=\u001b[32m'The above results were retrieved to help answer the user\\'s query: \"Kubernetes container startup error unknown error missing dependencies configuration errors\". Use them as supporting information only in answering this query.\\n'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 5: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"The logs indicate an error during container startup, and the knowledge search results suggest common issues like missing dependencies, configuration errors, or permission problems. Based on this, I will summarize the steps to take and prepare a message to send to the 'demos' channel on Slack.\", \"action\": {\"tool_name\": \"slack_post_message\", \"tool_params\": [{\"name\": \"channel_id\", \"value\": \"demos\"}, {\"name\": \"text\", \"value\": \"The 'slack-test' pod in the 'llama-serve' namespace encountered an error during startup. The error is categorized as a container startup failure, likely due to missing dependencies, configuration errors, or permission issues. Steps to resolve include checking the pod's configuration, verifying dependencies, and ensuring proper permissions. For detailed troubleshooting, review the logs and consider redeploying the pod after fixing the underlying issues.\"}]}, \"answer\": null}\n",
      "\u001b[0m\n",
      "\n",
      "---------- 📍 Step 6: ToolExecutionStep ----------\n",
      "🔧 Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":{\"warnings\":[\"missing_charset\"]}}'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"ok\":false,\"error\":\"invalid_auth\",\"warning\":\"missing_charset\",\"response_metadata\":\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"warnings\":\u001b[0m\u001b[32m[\u001b[0m\u001b[32m\"missing_charset\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- 📍 Step 7: InferenceStep ----------\n",
      "🤖 Model Response:\n",
      "\u001b[35m{\"thought\": \"The response indicates an authentication error when trying to post to Slack. I need to ensure that the correct authentication token is configured for the Slack API. Since I cannot reconfigure authentication directly, I will inform the user of the issue and suggest checking the Slack API credentials.\", \"action\": null, \"answer\": \"There was an authentication error when attempting to send the message to the 'demos' channel on Slack. Please verify that the correct Slack API credentials are configured and try again.\"}\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "builtin_rag = dict(\n",
    "            name=\"builtin::rag\",\n",
    "            args={\n",
    "                \"vector_db_ids\": [vector_db_id],  # list of IDs of document collections to consider during retrieval\n",
    "            },\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "agent = ReActAgent(\n",
    "            client=client,\n",
    "            model=model_id,\n",
    "            tools=[\"mcp::slack\",\"mcp::openshift\", builtin_rag],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": ReActOutput.model_json_schema(),\n",
    "            },\n",
    "            sampling_params={\"max_tokens\":512},\n",
    "        )\n",
    "\n",
    "user_prompts = [\"\"\"View the logs for pod slack-test in the llama-serve OpenShift namespace. Categorize it as normal or error, \n",
    "                search for solutions on this error and provide a summary of the steps to take in just 1-2 sentences.\n",
    "                Send a message with the summarization to the demos channel on Slack. Let me know when you've sent the message.\n",
    "                \"\"\"\n",
    "                ]\n",
    "\n",
    "session_id = agent.create_session(\"web-session\")\n",
    "for prompt in user_prompts:\n",
    "    print(\"\\n\"+\"=\"*50)\n",
    "    cprint(f\"Processing user query: {prompt}\", \"blue\")\n",
    "    print(\"=\"*50)\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4147a",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Above, we can see that the ReAct agent took nearly an identical approach to the prompt chaining method above, but using a single prompt instead of a chain.\n",
    "\n",
    "1. First, the agent reasoned that it needed to generated a tool call for the `pods_log` tool included in the OpenShift MCP server and did so to generate a tool call that fetched the logs for the specified pod.\n",
    "2. Next, the agent reasoned that its next step was to query the available vector database for more information about the logs and acted using the built-in `knowledge_search` tool. \n",
    "4. Then, the agent summarized the findings from the the knowledge search step and reasoned it needed to send a slack message to share this information with the team and did so by using the `slack_post_message` tool call configured with the Slack MCP server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105c368",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This tutorial demonstrates how to implement agentic RAG and MCP applications with Llama Stack. We do so by initializing an agent while giving it access to the MCP tools, and RAG tool configured with Llama Stack, then invoking the agent on the specified query. We showed that we can do this with more directed Prompt Chaining or with the more open ended ReAct pattern Please check out our other notebooks for more examples using Llama Stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991b679",
   "metadata": {},
   "source": [
    "#### Any Feedback?\n",
    "\n",
    "If you have any feedback on this or any other notebook in this demo series we'd love to hear it! Please go to https://www.feedback.redhat.com/jfe/form/SV_8pQsoy0U9Ccqsvk and help us improve our demos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c9972-9e72-46f7-a655-05912a14b702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
